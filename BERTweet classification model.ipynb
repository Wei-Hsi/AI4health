{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hsuweic/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load BERTweet model and tokenizer\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "hate_categories = 9  # Number of classes/categories\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=hate_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1430, 5)\n",
      "Index(['Unnamed: 0', 'tweet', 'label', 'categories', 'cleaned_tweet'], dtype='object')\n",
      "1430\n"
     ]
    }
   ],
   "source": [
    "import preprocessor\n",
    "import demoji\n",
    "import pandas as pd\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "def preprocess_text(text):\n",
    "    # Use tweet-preprocessor to clean tweets\n",
    "    cleaned_text = preprocessor.clean(text)\n",
    "    # Remove emojis\n",
    "    cleaned_text = remove_emojis(cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return demoji.replace(text, '')\n",
    "\n",
    "# Load your dataset with columns 'tweet' and 'categories'\n",
    "df = pd.read_csv(\"/Users/Hsuweic/Desktop/AI4healthcare/dataset/dataset_categories.csv\")\n",
    "hate_speech = df[df['label'] == 1].copy() \n",
    "# Reset the index to ensure it is consecutive\n",
    "hate_speech.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Preprocess text\n",
    "hate_speech['cleaned_tweet'] = hate_speech['tweet'].apply(preprocess_text)\n",
    "\n",
    "print(hate_speech.shape)\n",
    "print(hate_speech.columns)\n",
    "print(len(hate_speech))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "[0 1 2 3 4 5 6 7 8]\n",
      "1430\n",
      "0       [input_ids, token_type_ids, attention_mask]\n",
      "1       [input_ids, token_type_ids, attention_mask]\n",
      "2       [input_ids, token_type_ids, attention_mask]\n",
      "3       [input_ids, token_type_ids, attention_mask]\n",
      "4       [input_ids, token_type_ids, attention_mask]\n",
      "                           ...                     \n",
      "1425    [input_ids, token_type_ids, attention_mask]\n",
      "1426    [input_ids, token_type_ids, attention_mask]\n",
      "1427    [input_ids, token_type_ids, attention_mask]\n",
      "1428    [input_ids, token_type_ids, attention_mask]\n",
      "1429    [input_ids, token_type_ids, attention_mask]\n",
      "Name: cleaned_tweet, Length: 1430, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and prepare input data\n",
    "max_length = 128  # You can adjust this based on your requirements\n",
    "\n",
    "def tokenize_data(text):\n",
    "    return tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Tokenize input data\n",
    "tokenized_data = hate_speech['cleaned_tweet'].apply(tokenize_data)\n",
    "\n",
    "# Convert categories to numerical labels\n",
    "label_dict = {category: idx for idx, category in enumerate(hate_speech['categories'].unique())}\n",
    "hate_speech['label'] = hate_speech['categories'].map(label_dict)\n",
    "\n",
    "# Print label_dict to see the mapping\n",
    "print(\"Label Dictionary:\")\n",
    "print(label_dict)\n",
    "# print(hate_speech['label'].unique())\n",
    "print(len(tokenized_data))\n",
    "print(tokenized_data)\n",
    "\n",
    "# Prepare input tensors\n",
    "input_ids = torch.cat([tokenized_data[i]['input_ids'] for i in range(len(tokenized_data))], dim=0)\n",
    "attention_masks = torch.cat([tokenized_data[i]['attention_mask'] for i in range(len(tokenized_data))], dim=0)\n",
    "labels = torch.tensor(hate_speech['label'].values)\n",
    "\n",
    "# Create DataLoader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "=== Start Batch 0 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "1.2722333669662476\n",
      "=== Start Batch 1 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "1.6686564087867737\n",
      "=== Start Batch 2 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "2.858840048313141\n",
      "=== Start Batch 3 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "4.184438526630402\n",
      "=== Start Batch 4 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "5.213654577732086\n",
      "=== Start Batch 5 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "5.620341658592224\n",
      "=== Start Batch 6 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "6.368605434894562\n",
      "=== Start Batch 7 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "6.951549768447876\n",
      "=== Start Batch 8 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.183457851409912\n",
      "=== Start Batch 9 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.590369641780853\n",
      "=== Start Batch 10 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "10.451944410800934\n",
      "=== Start Batch 11 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "12.544727146625519\n",
      "=== Start Batch 12 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "13.282141983509064\n",
      "=== Start Batch 13 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "13.858945786952972\n",
      "=== Start Batch 14 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "14.65493255853653\n",
      "=== Start Batch 15 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "16.027741849422455\n",
      "=== Start Batch 16 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "16.549205124378204\n",
      "=== Start Batch 17 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "17.227923154830933\n",
      "=== Start Batch 18 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "17.862205624580383\n",
      "=== Start Batch 19 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "18.35251760482788\n",
      "=== Start Batch 20 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "19.76468336582184\n",
      "=== Start Batch 21 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "20.80321443080902\n",
      "=== Start Batch 22 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "21.575423657894135\n",
      "=== Start Batch 23 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "22.061688363552094\n",
      "=== Start Batch 24 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "22.709253549575806\n",
      "=== Start Batch 25 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "24.067392587661743\n",
      "=== Start Batch 26 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "24.664491832256317\n",
      "=== Start Batch 27 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.266059398651123\n",
      "=== Start Batch 28 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.85488599538803\n",
      "=== Start Batch 29 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.114263355731964\n",
      "=== Start Batch 30 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.966608345508575\n",
      "=== Start Batch 31 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "29.104251086711884\n",
      "=== Start Batch 32 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "30.150124728679657\n",
      "=== Start Batch 33 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "31.445950090885162\n",
      "=== Start Batch 34 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "31.957398414611816\n",
      "=== Start Batch 35 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "32.913907170295715\n",
      "=== Start Batch 36 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "34.23049986362457\n",
      "=== Start Batch 37 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.26795482635498\n",
      "=== Start Batch 38 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "36.19155955314636\n",
      "=== Start Batch 39 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "37.020766615867615\n",
      "=== Start Batch 40 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "37.720071613788605\n",
      "=== Start Batch 41 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "38.34742611646652\n",
      "=== Start Batch 42 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.9600870013237\n",
      "=== Start Batch 43 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "40.39570653438568\n",
      "=== Start Batch 44 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "41.27606475353241\n",
      "=== Start Batch 45 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "41.67244705557823\n",
      "=== Start Batch 46 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "42.28122541308403\n",
      "=== Start Batch 47 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "43.72148522734642\n",
      "=== Start Batch 48 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "43.82663991302252\n",
      "=== Start Batch 49 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "44.420035265386105\n",
      "=== Start Batch 50 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "45.170126639306545\n",
      "=== Start Batch 51 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "45.806117318570614\n",
      "=== Start Batch 52 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "47.295826219022274\n",
      "=== Start Batch 53 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "48.588694117963314\n",
      "=== Start Batch 54 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "48.87103684991598\n",
      "=== Start Batch 55 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "49.283652387559414\n",
      "=== Start Batch 56 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "50.26048590987921\n",
      "=== Start Batch 57 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "51.74808361381292\n",
      "=== Start Batch 58 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "52.94324292987585\n",
      "=== Start Batch 59 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "53.646613381803036\n",
      "=== Start Batch 60 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "54.25229438394308\n",
      "=== Start Batch 61 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.4964564666152\n",
      "=== Start Batch 62 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "56.04241742938757\n",
      "=== Start Batch 63 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "57.10176970809698\n",
      "=== Start Batch 64 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "58.015348218381405\n",
      "=== Start Batch 65 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "58.41087871044874\n",
      "=== Start Batch 66 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "58.797835640609264\n",
      "=== Start Batch 67 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "59.361614279448986\n",
      "=== Start Batch 68 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "60.716846995055676\n",
      "=== Start Batch 69 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "61.67627351731062\n",
      "=== Start Batch 70 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "62.55297815054655\n",
      "=== Start Batch 71 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "63.31096624583006\n",
      "=== Start Batch 72 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "64.0489287301898\n",
      "=== Start Batch 73 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "64.71032726019621\n",
      "=== Start Batch 74 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "65.39662181586027\n",
      "=== Start Batch 75 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.152517311275\n",
      "=== Start Batch 76 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.29256192594767\n",
      "=== Start Batch 77 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.64010686427355\n",
      "=== Start Batch 78 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.04108051210642\n",
      "=== Start Batch 79 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "68.07666126638651\n",
      "=== Start Batch 80 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "68.57192105799913\n",
      "=== Start Batch 81 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "68.7995241805911\n",
      "=== Start Batch 82 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "69.09510635584593\n",
      "=== Start Batch 83 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "69.62429117411375\n",
      "=== Start Batch 84 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "69.78530562669039\n",
      "=== Start Batch 85 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "70.40574974566698\n",
      "=== Start Batch 86 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "71.43958396464586\n",
      "=== Start Batch 87 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "72.30509609729052\n",
      "=== Start Batch 88 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "73.01601142436266\n",
      "=== Start Batch 89 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "73.58909601718187\n",
      "=== Start Batch 90 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "74.01494760066271\n",
      "=== Start Batch 91 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "74.4703233614564\n",
      "=== Start Batch 92 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "74.78000874072313\n",
      "=== Start Batch 93 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "75.53808844834566\n",
      "=== Start Batch 94 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "76.1590790823102\n",
      "=== Start Batch 95 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "77.07903326302767\n",
      "=== Start Batch 96 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "78.5848466232419\n",
      "=== Start Batch 97 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "80.35370147973299\n",
      "=== Start Batch 98 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "80.81769213825464\n",
      "=== Start Batch 99 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "81.19982052594423\n",
      "=== Start Batch 100 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "81.81661558896303\n",
      "=== Start Batch 101 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "82.27220282703638\n",
      "=== Start Batch 102 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "82.71270317584276\n",
      "=== Start Batch 103 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "83.18313992768526\n",
      "=== Start Batch 104 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "84.18013889342546\n",
      "=== Start Batch 105 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "84.70458526164293\n",
      "=== Start Batch 106 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "85.82378584891558\n",
      "=== Start Batch 107 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "86.76872576028109\n",
      "=== Start Batch 108 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "87.55513561517\n",
      "=== Start Batch 109 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "88.04280579835176\n",
      "=== Start Batch 110 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "88.56233573704958\n",
      "=== Start Batch 111 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "89.14670164138079\n",
      "=== Start Batch 112 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "90.20468956977129\n",
      "=== Start Batch 113 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "90.69217652827501\n",
      "=== Start Batch 114 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "91.2871598675847\n",
      "=== Start Batch 115 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "91.6852729395032\n",
      "=== Start Batch 116 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "92.88566256314516\n",
      "=== Start Batch 117 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "93.5229861214757\n",
      "=== Start Batch 118 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "93.99327636510134\n",
      "=== Start Batch 119 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "95.09296680241823\n",
      "=== Start Batch 120 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "96.19875837117434\n",
      "=== Start Batch 121 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "97.34378600865602\n",
      "=== Start Batch 122 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "97.9039698317647\n",
      "=== Start Batch 123 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "98.86531097441912\n",
      "=== Start Batch 124 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "99.62591172009706\n",
      "=== Start Batch 125 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "100.39901126176119\n",
      "=== Start Batch 126 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "100.92881876975298\n",
      "=== Start Batch 127 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "102.34084243327379\n",
      "=== Start Batch 128 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "102.8341860845685\n",
      "=== Start Batch 129 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "103.98061538487673\n",
      "=== Start Batch 130 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "104.86991573125124\n",
      "=== Start Batch 131 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "106.81573272496462\n",
      "=== Start Batch 132 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "108.44034946709871\n",
      "=== Start Batch 133 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "108.87521163374186\n",
      "=== Start Batch 134 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "110.38689462095499\n",
      "=== Start Batch 135 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "111.86472741514444\n",
      "=== Start Batch 136 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "112.35079804807901\n",
      "=== Start Batch 137 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "113.10025081783533\n",
      "=== Start Batch 138 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "113.65627608448267\n",
      "=== Start Batch 139 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "114.45993838459253\n",
      "=== Start Batch 140 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "115.35022733360529\n",
      "=== Start Batch 141 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "116.21938583999872\n",
      "=== Start Batch 142 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "117.5652740970254\n",
      "=== Start Batch 143 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "117.94448257237673\n",
      "=== Start Batch 144 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "118.71853447705507\n",
      "=== Start Batch 145 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "118.97771591693163\n",
      "=== Start Batch 146 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "119.5897888019681\n",
      "=== Start Batch 147 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "120.07127249985933\n",
      "=== Start Batch 148 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "120.36738038808107\n",
      "=== Start Batch 149 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "121.490478284657\n",
      "=== Start Batch 150 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "123.35068000108004\n",
      "=== Start Batch 151 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "123.7997753098607\n",
      "=== Start Batch 152 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "124.56097770482302\n",
      "=== Start Batch 153 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "125.58220804482698\n",
      "=== Start Batch 154 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "126.39937175065279\n",
      "=== Start Batch 155 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "126.83129910379648\n",
      "=== Start Batch 156 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "126.93736354261637\n",
      "=== Start Batch 157 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "127.75132486969233\n",
      "=== Start Batch 158 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "127.92932031303644\n",
      "=== Start Batch 159 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "128.6305047646165\n",
      "=== Start Batch 160 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "128.80257821828127\n",
      "=== Start Batch 161 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "129.391840942204\n",
      "=== Start Batch 162 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "129.74961654096842\n",
      "=== Start Batch 163 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "130.0879815891385\n",
      "=== Start Batch 164 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "130.1718864440918\n",
      "=== Start Batch 165 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "130.5253935456276\n",
      "=== Start Batch 166 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "130.74337393045425\n",
      "=== Start Batch 167 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "130.8510916084051\n",
      "=== Start Batch 168 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "131.21796317398548\n",
      "=== Start Batch 169 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "131.68694759905338\n",
      "=== Start Batch 170 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "132.34146822988987\n",
      "=== Start Batch 171 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "133.04455383121967\n",
      "=== Start Batch 172 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "133.3429761081934\n",
      "=== Start Batch 173 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "133.7157411724329\n",
      "=== Start Batch 174 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "133.93102027475834\n",
      "=== Start Batch 175 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "134.60477162897587\n",
      "=== Start Batch 176 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "135.2807561904192\n",
      "=== Start Batch 177 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "135.7715249210596\n",
      "=== Start Batch 178 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "136.37880124151707\n",
      "Epoch 1/3, Loss: 0.7618927443660172\n",
      "Start Training\n",
      "=== Start Batch 0 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "0.48157522082328796\n",
      "=== Start Batch 1 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "0.7293336987495422\n",
      "=== Start Batch 2 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "1.1961562931537628\n",
      "=== Start Batch 3 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "2.119389921426773\n",
      "=== Start Batch 4 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "3.428164154291153\n",
      "=== Start Batch 5 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "3.5231403559446335\n",
      "=== Start Batch 6 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "3.9712917655706406\n",
      "=== Start Batch 7 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "4.096281938254833\n",
      "=== Start Batch 8 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "4.5669248923659325\n",
      "=== Start Batch 9 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "5.51493277400732\n",
      "=== Start Batch 10 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "5.737900905311108\n",
      "=== Start Batch 11 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "6.675833694636822\n",
      "=== Start Batch 12 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "7.1729215905070305\n",
      "=== Start Batch 13 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.017430417239666\n",
      "=== Start Batch 14 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.201144643127918\n",
      "=== Start Batch 15 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "9.140999384224415\n",
      "=== Start Batch 16 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "9.373576037585735\n",
      "=== Start Batch 17 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "9.991495244204998\n",
      "=== Start Batch 18 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "11.678351037204266\n",
      "=== Start Batch 19 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "11.816882975399494\n",
      "=== Start Batch 20 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "12.177048780024052\n",
      "=== Start Batch 21 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "13.087579764425755\n",
      "=== Start Batch 22 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "13.463786132633686\n",
      "=== Start Batch 23 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "14.386264868080616\n",
      "=== Start Batch 24 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "14.844406463205814\n",
      "=== Start Batch 25 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "15.949475981295109\n",
      "=== Start Batch 26 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "16.237269140779972\n",
      "=== Start Batch 27 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "16.73321906477213\n",
      "=== Start Batch 28 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "17.838899292051792\n",
      "=== Start Batch 29 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "18.0403266325593\n",
      "=== Start Batch 30 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "18.32096440345049\n",
      "=== Start Batch 31 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "19.35113937407732\n",
      "=== Start Batch 32 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "20.017186410725117\n",
      "=== Start Batch 33 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "20.4725636318326\n",
      "=== Start Batch 34 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "21.193735606968403\n",
      "=== Start Batch 35 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "21.64643207937479\n",
      "=== Start Batch 36 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "22.8100563660264\n",
      "=== Start Batch 37 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "23.494678534567356\n",
      "=== Start Batch 38 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "23.971482165157795\n",
      "=== Start Batch 39 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "24.57609076052904\n",
      "=== Start Batch 40 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "24.81023893505335\n",
      "=== Start Batch 41 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.471460916101933\n",
      "=== Start Batch 42 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.744504876434803\n",
      "=== Start Batch 43 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.898177854716778\n",
      "=== Start Batch 44 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.995639137923717\n",
      "=== Start Batch 45 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "26.52083008736372\n",
      "=== Start Batch 46 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "26.789559446275234\n",
      "=== Start Batch 47 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.013563595712185\n",
      "=== Start Batch 48 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.984477125108242\n",
      "=== Start Batch 49 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "28.283569268882275\n",
      "=== Start Batch 50 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "28.61252423375845\n",
      "=== Start Batch 51 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "29.291983388364315\n",
      "=== Start Batch 52 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "29.389737017452717\n",
      "=== Start Batch 53 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "29.848721213638783\n",
      "=== Start Batch 54 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "30.907906003296375\n",
      "=== Start Batch 55 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "31.13284371048212\n",
      "=== Start Batch 56 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "32.11975107342005\n",
      "=== Start Batch 57 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "32.66333345323801\n",
      "=== Start Batch 58 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "32.751308403909206\n",
      "=== Start Batch 59 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "33.592126809060574\n",
      "=== Start Batch 60 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "33.76353328675032\n",
      "=== Start Batch 61 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "34.35384427756071\n",
      "=== Start Batch 62 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "34.573879055678844\n",
      "=== Start Batch 63 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "34.955122493207455\n",
      "=== Start Batch 64 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.2320276722312\n",
      "=== Start Batch 65 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.62213438004255\n",
      "=== Start Batch 66 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.70819749683142\n",
      "=== Start Batch 67 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "36.23503329604864\n",
      "=== Start Batch 68 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "36.35362198203802\n",
      "=== Start Batch 69 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "37.963428638875484\n",
      "=== Start Batch 70 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "38.57352354377508\n",
      "=== Start Batch 71 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.53038563579321\n",
      "=== Start Batch 72 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.71185541898012\n",
      "=== Start Batch 73 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.77488350868225\n",
      "=== Start Batch 74 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.91704575717449\n",
      "=== Start Batch 75 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "40.04955218732357\n",
      "=== Start Batch 76 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "41.17391334474087\n",
      "=== Start Batch 77 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "41.2228917889297\n",
      "=== Start Batch 78 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "41.3232380412519\n",
      "=== Start Batch 79 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "42.728578951209784\n",
      "=== Start Batch 80 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "42.90614390000701\n",
      "=== Start Batch 81 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "43.32946151122451\n",
      "=== Start Batch 82 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "43.64863100275397\n",
      "=== Start Batch 83 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "43.89802109822631\n",
      "=== Start Batch 84 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "44.49000388011336\n",
      "=== Start Batch 85 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "45.29909413680434\n",
      "=== Start Batch 86 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "45.7521272264421\n",
      "=== Start Batch 87 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "46.33332693204284\n",
      "=== Start Batch 88 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "47.2102034650743\n",
      "=== Start Batch 89 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "48.01682889088988\n",
      "=== Start Batch 90 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "48.46879407390952\n",
      "=== Start Batch 91 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "49.341768469661474\n",
      "=== Start Batch 92 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "49.966516461223364\n",
      "=== Start Batch 93 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "50.442144211381674\n",
      "=== Start Batch 94 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "50.49634828418493\n",
      "=== Start Batch 95 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "51.91317691653967\n",
      "=== Start Batch 96 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "52.11289831250906\n",
      "=== Start Batch 97 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "52.84892150014639\n",
      "=== Start Batch 98 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "52.90613892674446\n",
      "=== Start Batch 99 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "53.47374340891838\n",
      "=== Start Batch 100 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "54.60156521201134\n",
      "=== Start Batch 101 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.21461620926857\n",
      "=== Start Batch 102 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.602711886167526\n",
      "=== Start Batch 103 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.84292145073414\n",
      "=== Start Batch 104 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.92723918706179\n",
      "=== Start Batch 105 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "56.43789417296648\n",
      "=== Start Batch 106 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "57.1678527072072\n",
      "=== Start Batch 107 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "57.85589171200991\n",
      "=== Start Batch 108 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "59.05334151536226\n",
      "=== Start Batch 109 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "59.89563686400652\n",
      "=== Start Batch 110 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "60.02343162149191\n",
      "=== Start Batch 111 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "61.326458655297756\n",
      "=== Start Batch 112 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "61.57264482229948\n",
      "=== Start Batch 113 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "62.17497169226408\n",
      "=== Start Batch 114 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "63.19401203840971\n",
      "=== Start Batch 115 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "63.282350704073906\n",
      "=== Start Batch 116 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "63.494339779019356\n",
      "=== Start Batch 117 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "64.28240920603275\n",
      "=== Start Batch 118 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "64.35134004056454\n",
      "=== Start Batch 119 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "65.01793025434017\n",
      "=== Start Batch 120 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "65.6252468675375\n",
      "=== Start Batch 121 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "65.7741900831461\n",
      "=== Start Batch 122 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.09689496457577\n",
      "=== Start Batch 123 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.1993410512805\n",
      "=== Start Batch 124 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.31042408198118\n",
      "=== Start Batch 125 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.76276870816946\n",
      "=== Start Batch 126 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.93979861587286\n",
      "=== Start Batch 127 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.02138079702854\n",
      "=== Start Batch 128 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.18555752933025\n",
      "=== Start Batch 129 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.85301278531551\n",
      "=== Start Batch 130 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "68.7185337394476\n",
      "=== Start Batch 131 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "69.57626889646053\n",
      "=== Start Batch 132 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "69.73117850720882\n",
      "=== Start Batch 133 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "69.89593681693077\n",
      "=== Start Batch 134 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "70.904750674963\n",
      "=== Start Batch 135 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "72.36097452044487\n",
      "=== Start Batch 136 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "72.59298598766327\n",
      "=== Start Batch 137 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "72.75391265749931\n",
      "=== Start Batch 138 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "72.88513174653053\n",
      "=== Start Batch 139 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "73.06182461977005\n",
      "=== Start Batch 140 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "73.44652804732323\n",
      "=== Start Batch 141 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "73.78932908177376\n",
      "=== Start Batch 142 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "73.86517476290464\n",
      "=== Start Batch 143 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "74.22368233650923\n",
      "=== Start Batch 144 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "74.81476121395826\n",
      "=== Start Batch 145 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "74.94458591192961\n",
      "=== Start Batch 146 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "75.6686597391963\n",
      "=== Start Batch 147 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "75.80255929380655\n",
      "=== Start Batch 148 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "76.46511069685221\n",
      "=== Start Batch 149 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "76.77993319183588\n",
      "=== Start Batch 150 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "76.81805330887437\n",
      "=== Start Batch 151 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "77.75438535586\n",
      "=== Start Batch 152 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "78.3316341675818\n",
      "=== Start Batch 153 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "78.75840136781335\n",
      "=== Start Batch 154 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "79.06557673588395\n",
      "=== Start Batch 155 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "79.30314222350717\n",
      "=== Start Batch 156 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "79.35311657562852\n",
      "=== Start Batch 157 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "79.45518549904227\n",
      "=== Start Batch 158 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "80.38920434936881\n",
      "=== Start Batch 159 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "81.61252936348319\n",
      "=== Start Batch 160 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "82.09840148314834\n",
      "=== Start Batch 161 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "82.21888924762607\n",
      "=== Start Batch 162 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "82.61604998633265\n",
      "=== Start Batch 163 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "83.4040441326797\n",
      "=== Start Batch 164 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "83.70801563188434\n",
      "=== Start Batch 165 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "85.1377925388515\n",
      "=== Start Batch 166 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "85.59148446843028\n",
      "=== Start Batch 167 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "86.2231764011085\n",
      "=== Start Batch 168 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "86.99028549715877\n",
      "=== Start Batch 169 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "87.09601253643632\n",
      "=== Start Batch 170 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "88.0178261436522\n",
      "=== Start Batch 171 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "88.71928286924958\n",
      "=== Start Batch 172 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "89.55678183212876\n",
      "=== Start Batch 173 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "89.99421635642648\n",
      "=== Start Batch 174 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "90.41683742776513\n",
      "=== Start Batch 175 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "91.32402143254876\n",
      "=== Start Batch 176 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "91.42368481680751\n",
      "=== Start Batch 177 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "91.92863730713725\n",
      "=== Start Batch 178 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "92.0217934884131\n",
      "Epoch 2/3, Loss: 0.5140882317788441\n",
      "Start Training\n",
      "=== Start Batch 0 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "1.4785370826721191\n",
      "=== Start Batch 1 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "2.066471815109253\n",
      "=== Start Batch 2 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "2.8484005331993103\n",
      "=== Start Batch 3 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "2.896490816026926\n",
      "=== Start Batch 4 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "2.9716541655361652\n",
      "=== Start Batch 5 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "3.789033342152834\n",
      "=== Start Batch 6 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "3.8639067225158215\n",
      "=== Start Batch 7 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "3.946050178259611\n",
      "=== Start Batch 8 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "4.723962377756834\n",
      "=== Start Batch 9 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "5.243143390864134\n",
      "=== Start Batch 10 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "5.818720828741789\n",
      "=== Start Batch 11 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "6.229743015021086\n",
      "=== Start Batch 12 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "6.349870141595602\n",
      "=== Start Batch 13 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "7.067888554185629\n",
      "=== Start Batch 14 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "7.132989678531885\n",
      "=== Start Batch 15 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "7.729737315326929\n",
      "=== Start Batch 16 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "7.936014134436846\n",
      "=== Start Batch 17 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.047200325876474\n",
      "=== Start Batch 18 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.218331564217806\n",
      "=== Start Batch 19 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.367900539189577\n",
      "=== Start Batch 20 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.418578308075666\n",
      "=== Start Batch 21 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "8.692893546074629\n",
      "=== Start Batch 22 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "9.142887961119413\n",
      "=== Start Batch 23 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "9.262179400771856\n",
      "=== Start Batch 24 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "10.229651656001806\n",
      "=== Start Batch 25 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "10.591374929994345\n",
      "=== Start Batch 26 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "10.835304748266935\n",
      "=== Start Batch 27 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "11.000924285501242\n",
      "=== Start Batch 28 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "11.229433413594961\n",
      "=== Start Batch 29 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "11.6661340855062\n",
      "=== Start Batch 30 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "12.402188207954168\n",
      "=== Start Batch 31 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "12.86100473627448\n",
      "=== Start Batch 32 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "13.498389091342688\n",
      "=== Start Batch 33 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "14.288767244666815\n",
      "=== Start Batch 34 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "14.611327614635229\n",
      "=== Start Batch 35 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "14.786435838788748\n",
      "=== Start Batch 36 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "15.616544838994741\n",
      "=== Start Batch 37 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "15.670779284089804\n",
      "=== Start Batch 38 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "15.760684866458178\n",
      "=== Start Batch 39 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "16.34150977805257\n",
      "=== Start Batch 40 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "16.794323671609163\n",
      "=== Start Batch 41 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "17.264454949647188\n",
      "=== Start Batch 42 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "17.40543495491147\n",
      "=== Start Batch 43 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "17.81546976044774\n",
      "=== Start Batch 44 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "19.034017343074083\n",
      "=== Start Batch 45 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "20.088360089808702\n",
      "=== Start Batch 46 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "20.128274250775576\n",
      "=== Start Batch 47 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "20.357545647770166\n",
      "=== Start Batch 48 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "20.41518683731556\n",
      "=== Start Batch 49 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "21.21441902220249\n",
      "=== Start Batch 50 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "21.733309879899025\n",
      "=== Start Batch 51 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "22.016387417912483\n",
      "=== Start Batch 52 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "22.390831783413887\n",
      "=== Start Batch 53 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "22.713586643338203\n",
      "=== Start Batch 54 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "23.456775084137917\n",
      "=== Start Batch 55 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "23.889601603150368\n",
      "=== Start Batch 56 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "24.698360577225685\n",
      "=== Start Batch 57 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "24.911003440618515\n",
      "=== Start Batch 58 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.40060791373253\n",
      "=== Start Batch 59 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.519400477409363\n",
      "=== Start Batch 60 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.774767458438873\n",
      "=== Start Batch 61 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "25.930754110217094\n",
      "=== Start Batch 62 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "26.007714115083218\n",
      "=== Start Batch 63 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "26.09028222411871\n",
      "=== Start Batch 64 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "26.39029299467802\n",
      "=== Start Batch 65 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "26.478019133210182\n",
      "=== Start Batch 66 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.40053053200245\n",
      "=== Start Batch 67 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.445424783974886\n",
      "=== Start Batch 68 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.648431453853846\n",
      "=== Start Batch 69 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.769605953246355\n",
      "=== Start Batch 70 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.883673768490553\n",
      "=== Start Batch 71 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "27.91660140827298\n",
      "=== Start Batch 72 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "28.361956615000963\n",
      "=== Start Batch 73 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "29.1052075214684\n",
      "=== Start Batch 74 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "29.641714114695787\n",
      "=== Start Batch 75 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "29.71366662159562\n",
      "=== Start Batch 76 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "30.13354665413499\n",
      "=== Start Batch 77 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "30.777318600565195\n",
      "=== Start Batch 78 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "30.92414954677224\n",
      "=== Start Batch 79 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "30.957934446632862\n",
      "=== Start Batch 80 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "31.608022399246693\n",
      "=== Start Batch 81 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "31.665378652513027\n",
      "=== Start Batch 82 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "33.23048683255911\n",
      "=== Start Batch 83 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "33.38091131299734\n",
      "=== Start Batch 84 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "34.30471505969763\n",
      "=== Start Batch 85 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "34.664954893291\n",
      "=== Start Batch 86 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "34.85298611968756\n",
      "=== Start Batch 87 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.317941181361675\n",
      "=== Start Batch 88 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.4596179202199\n",
      "=== Start Batch 89 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.56803468614817\n",
      "=== Start Batch 90 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.62845139205456\n",
      "=== Start Batch 91 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "35.82594898343086\n",
      "=== Start Batch 92 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "36.250062346458435\n",
      "=== Start Batch 93 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "36.40253295004368\n",
      "=== Start Batch 94 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "36.846337631344795\n",
      "=== Start Batch 95 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "36.936713352799416\n",
      "=== Start Batch 96 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "37.19095014035702\n",
      "=== Start Batch 97 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "38.317304357886314\n",
      "=== Start Batch 98 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "38.67787949740887\n",
      "=== Start Batch 99 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.41059683263302\n",
      "=== Start Batch 100 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.46925022825599\n",
      "=== Start Batch 101 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.64170264825225\n",
      "=== Start Batch 102 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "39.77198412641883\n",
      "=== Start Batch 103 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "40.64524241909385\n",
      "=== Start Batch 104 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "41.1116827391088\n",
      "=== Start Batch 105 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "41.75818171724677\n",
      "=== Start Batch 106 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "42.061421778053045\n",
      "=== Start Batch 107 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "42.57118770107627\n",
      "=== Start Batch 108 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "43.053531136363745\n",
      "=== Start Batch 109 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "43.45106318220496\n",
      "=== Start Batch 110 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "44.227680291980505\n",
      "=== Start Batch 111 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "44.37568536028266\n",
      "=== Start Batch 112 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "44.63168766722083\n",
      "=== Start Batch 113 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "45.77238443121314\n",
      "=== Start Batch 114 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "45.882736798375845\n",
      "=== Start Batch 115 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "46.33673691377044\n",
      "=== Start Batch 116 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "46.39296160265803\n",
      "=== Start Batch 117 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "46.44617537036538\n",
      "=== Start Batch 118 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "46.50808512791991\n",
      "=== Start Batch 119 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "46.611171793192625\n",
      "=== Start Batch 120 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "46.70989524200559\n",
      "=== Start Batch 121 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "47.42519234493375\n",
      "=== Start Batch 122 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "47.5503979511559\n",
      "=== Start Batch 123 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "47.676271233707666\n",
      "=== Start Batch 124 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "47.8442574031651\n",
      "=== Start Batch 125 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "48.312923271209\n",
      "=== Start Batch 126 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "48.39629115536809\n",
      "=== Start Batch 127 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "48.536160577088594\n",
      "=== Start Batch 128 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "49.30165462568402\n",
      "=== Start Batch 129 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "50.25318377092481\n",
      "=== Start Batch 130 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "51.26571576669812\n",
      "=== Start Batch 131 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "52.05345909669995\n",
      "=== Start Batch 132 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "52.17318831011653\n",
      "=== Start Batch 133 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "52.920021276921034\n",
      "=== Start Batch 134 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "53.571161430329084\n",
      "=== Start Batch 135 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "53.64517204836011\n",
      "=== Start Batch 136 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "53.81274803355336\n",
      "=== Start Batch 137 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "54.42122580483556\n",
      "=== Start Batch 138 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "54.68299962952733\n",
      "=== Start Batch 139 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "54.78174835816026\n",
      "=== Start Batch 140 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.2483485378325\n",
      "=== Start Batch 141 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.383801747113466\n",
      "=== Start Batch 142 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.62695277109742\n",
      "=== Start Batch 143 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "55.98504960909486\n",
      "=== Start Batch 144 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "56.04121171683073\n",
      "=== Start Batch 145 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "56.17131399363279\n",
      "=== Start Batch 146 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "56.27752712368965\n",
      "=== Start Batch 147 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "56.974416464567184\n",
      "=== Start Batch 148 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "57.536729365587234\n",
      "=== Start Batch 149 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "57.743982300162315\n",
      "=== Start Batch 150 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "57.86700140684843\n",
      "=== Start Batch 151 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "57.91386654227972\n",
      "=== Start Batch 152 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "58.58895470947027\n",
      "=== Start Batch 153 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "58.69134031236172\n",
      "=== Start Batch 154 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "59.94529400765896\n",
      "=== Start Batch 155 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "60.508924052119255\n",
      "=== Start Batch 156 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "61.38551042973995\n",
      "=== Start Batch 157 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "62.731096372008324\n",
      "=== Start Batch 158 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "62.79362031072378\n",
      "=== Start Batch 159 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "63.150511376559734\n",
      "=== Start Batch 160 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "64.08097403496504\n",
      "=== Start Batch 161 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "64.90052848309278\n",
      "=== Start Batch 162 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "65.10406742244959\n",
      "=== Start Batch 163 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "65.90129408985376\n",
      "=== Start Batch 164 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.3980962112546\n",
      "=== Start Batch 165 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "66.99093223363161\n",
      "=== Start Batch 166 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.02316236495972\n",
      "=== Start Batch 167 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.10906916856766\n",
      "=== Start Batch 168 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.19541957974434\n",
      "=== Start Batch 169 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.3381344974041\n",
      "=== Start Batch 170 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.46159920096397\n",
      "=== Start Batch 171 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.4984667301178\n",
      "=== Start Batch 172 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.67026786506176\n",
      "=== Start Batch 173 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "67.79394787549973\n",
      "=== Start Batch 174 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "68.0929681956768\n",
      "=== Start Batch 175 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "68.20044381916523\n",
      "=== Start Batch 176 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "68.50299002230167\n",
      "=== Start Batch 177 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "69.85472859442234\n",
      "=== Start Batch 178 ===\n",
      "Start Doing Gradients\n",
      "Start Forward\n",
      "Start Calculating Loss\n",
      "Start Backward\n",
      "Start Update Parameters\n",
      "70.5791427642107\n",
      "Epoch 3/3, Loss: 0.39429688695089776\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Set up training parameters\n",
    "num_epochs = 3  # You can adjust this based on your requirements\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model and data to the device\n",
    "model.to(device)\n",
    "input_ids, attention_masks, labels = input_ids.to(device), attention_masks.to(device), labels.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print(\"Start Training\")\n",
    "    total_loss = 0\n",
    "    n = 0\n",
    "    for batch in dataloader:\n",
    "        print(\"=== Start Batch \" + str(n) + \" ===\")\n",
    "        batch_input_ids, batch_attention_masks, batch_labels = batch\n",
    "        batch_input_ids, batch_attention_masks, batch_labels = (\n",
    "            batch_input_ids.to(device),\n",
    "            batch_attention_masks.to(device),\n",
    "            batch_labels.to(device),\n",
    "        )\n",
    "\n",
    "        # Zero the gradients\n",
    "        print(\"Start Doing Gradients\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        print(\"Start Forward\")\n",
    "        outputs = model(\n",
    "            input_ids=batch_input_ids,\n",
    "            attention_mask=batch_attention_masks,\n",
    "            labels=batch_labels,\n",
    "        )\n",
    "\n",
    "        # Calculate loss\n",
    "        print(\"Start Calculating Loss\")\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        print(\"Start Backward\")\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        print(\"Start Update Parameters\")\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        print(total_loss)\n",
    "\n",
    "        n = n+1\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}\")\n",
    "\n",
    "# Save the trained model (This method is specific to the transformers library and is designed for saving transformer-based models.\n",
    "# It saves the model in a format that includes the architecture, parameters, and additional information specific to the transformers library.\n",
    "# It provides a higher-level abstraction that is specific to transformer models and allows for easily loading the model using AutoModel.from_pretrained later.)\n",
    "model.save_pretrained(\"/Users/Hsuweic/Desktop/AI4health/model/BERTweet classification model\")\n",
    "tokenizer.save_pretrained(\"/Users/Hsuweic/Desktop/AI4health/model/BERTweet classification model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained model\n",
    "# batch size = 8\n",
    "# total training time = 160 mins\n",
    "# optimizer = AdamW\n",
    "# Epoch 1/3, Loss: 0.7618927443660172\n",
    "# Epoch 2/3, Loss: 0.5140882317788441\n",
    "# Epoch 3/3, Loss: 0.39429688695089776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inference\n",
    "Label Dictionary:\n",
    "{'Race': 0, 'Sexual Orientation': 1, 'Gender': 2, 'Religion': 3, 'Disability': 4, 'Physical Appearance': 5, 'Class': 6, 'Ethnicity': 7, 'Behavior': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Example input tweet\n",
    "input_tweet = \"you are a nasty bitch and I hate you\"\n",
    "\n",
    "# Load the BERTweet tokenizer and model\n",
    "model_path = \"/Users/Hsuweic/Desktop/AI4health/model/BERTweet classification model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=9)  # Assuming 9 classes\n",
    "\n",
    "# Tokenize the input tweet\n",
    "inputs = tokenizer(input_tweet, return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass through the model to obtain logits\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get logits from the output\n",
    "logits = outputs.logits\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "# Choose the predicted class\n",
    "predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
